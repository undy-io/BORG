
# ğŸ›°ï¸ BORG â€” Kubernetesâ€‘aware OpenAIÂ Loadâ€‘Balancing Proxy

> **BORG** turns a fleet of OpenAIâ€‘compatible backâ€‘ends (vLLM, openaiâ€‘proxy, FastAPI stubs, etc.) into **one** dropâ€‘in `/v1` endpoint. It autoâ€‘discovers pods in your cluster, fanâ€‘outs requests across them, and exposes the union of all models.

![CI](https://img.shields.io/github/actions/workflow/status/undy-io/BORG/docker.yml?logo=github\&label=Build)
![License](https://img.shields.io/github/license/undy-io/BORG)

---

## âœ¨ Features

|                           |                                                                                    |
| ------------------------- | ---------------------------------------------------------------------------------- |
| **Zeroâ€‘config discovery** | Finds pods matching a label selector and registers their models automatically      |
| **Multiâ€‘backend fanâ€‘out** | Routes any `/v1/*` call to the next healthy backend and returns the first success  |
| **Model union**           | `GET /v1/models` merges all discovered models                                      |
| **Pluggable auth**        | Optional AESâ€‘256 request signing (`auth_key`) and prefix rewriting (`auth_prefix`) |
| **Lightweight**           | FastAPIÂ +Â uvicorn on PythonÂ 3.12â€‘slim (<Â 40Â MB image)                              |
| **Helm chart & CI**       | Oneâ€‘line `helm upgrade` and GitHub Actions pipeline to GHCR                        |

---

## ğŸš€ QuickÂ start

### 1Â â€“ Run locally with Poetry

```bash
git clone https://github.com/undy-io/BORG.git
cd BORG
poetry install --no-root
cp config.example.yaml config.yaml      # edit at will
poetry run uvicorn borg.main:app --reload
```

### 2Â â€“ Docker

```bash
# Build & start
docker build -t borg:dev .
docker run -p 8000:8000 -v $PWD/config.yaml:/app/config.yaml borg:dev
```

### 3Â â€“ KinDÂ +Â Helm (offline loop)

```bash
kind create cluster --name borg-dev --config kind-config.yaml
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install ingress ingress-nginx/ingress-nginx --create-namespace --namespace ingress-nginx

# load the image straight into KinD
docker build -t ghcr.io/undy-io/borg:dev .
kind load docker-image ghcr.io/undy-io/borg:dev --name borg-dev

helm upgrade --install borg charts/borg \
  --set image.repository=ghcr.io/undy-io/borg \
  --set image.tag=dev
```

> Need a dummy backend? `helm install dummy-openai charts/dummy-openai` â€” Borg discovers it within seconds.

---

## âš™ï¸ Configuration

```yaml
# config.yaml
borg:
  auth_key: "EMPTY"                # base64â€‘url 32â€‘byte AESâ€‘256 key
  auth_prefix: "BORG:"             # prefix rewritten into Authorization
  update_interval: 30               # seconds between K8s discovery passes

  # Static backâ€‘ends
  instances:
    - endpoint: "http://10.0.0.5:8000"
      apikey: "sk-example"
      models: ["gpt-3.5-turbo"]

  # Dynamic discovery
  k8s_discover:
    - namespace: vllm-servers
      selector: borg/expose=vllm
      modelkey: borg/models          # pod annotation holding model list
```

The file can be mounted into the container or set via `PROXY_CONFIG` envâ€‘var. See `config.example.yaml` for a template.

---

## ğŸ› ï¸ Helm chart

```bash
helm show values charts/borg > my-values.yaml
# edit and deploy
helm upgrade --install borg charts/borg -f my-values.yaml
```

Key values

| Parameter          | Description                                   | Default                |
| ------------------ | --------------------------------------------- | ---------------------- |
| `image.repository` | Image to run                                  | `ghcr.io/undy-io/borg` |
| `ingress.enabled`  | Expose via Ingressâ€‘NGINX                      | `false`                |
| `ingress.hosts`    | DNS names served                              | `[]`                   |
| `config`           | Inline proxy config (overrides `config.yaml`) | `{}`                   |

---

## ğŸ–§ How discovery works

1. Each selector in `k8s_discover` is queried via the Kubernetes API.
2. For every **Running** pod, BORG builds an endpoint URL from the pod IP and annotations (`borg/apiport`, `borg/apibase`, `borg/protocol`).
3. If no model list is supplied, BORG calls the podâ€™s `/v1/models` to infer models.
4. New endpoints are registered; stale ones are evicted.

---

## ğŸ§ª Testing

```bash
pytest -q
```

Unit tests live under `tests/`.

---

## ğŸ“¦ Release workflow

* Pushes to **master** build `:edge` and `:sha-<short>` images.
* Tagging `vX.Y.Z` also produces `:latest`, `:X.Y`, and `:X.Y.Z` tags.
* CI pipeline lives in `.github/workflows/docker.yml`.

---

## ğŸ¤ Contributing

1. Fork & clone
2. `poetry install`
3. Make changes, add tests
4. `pre-commit run -a` (black, isort, flake8, mypy)
5. PR against **master**

---

## ğŸ“„ License

MIT â€” see `LICENSE` for details.

Appendix â€“ dev cheatâ€‘sheet
```bash
kind create cluster --name borg-dev --config kind-config.yaml
#we need cert manager
helm install cert-manager jetstack/cert-manager \
    --namespace cert-manager \
    --create-namespace \
    --version v1.18.2 \
    --set crds.enabled=true

podman build -t ghcr.io/undy-io/borg:dev .
rm -f borg.tar
podman save --format docker-archive -o borg.tar ghcr.io/undy-io/borg:dev
kind load image-archive borg.tar --name borg-dev
helm uninstall borg
helm upgrade --install borg charts/borg --set image.repository=ghcr.io/undy-io/borg --set image.tag=dev
kubectl logs -f deployment/borg-borg
# Start dummy if needed
```

---

Â©Â 2025Â MichaelÂ C.Â McMinn â€¢ Contributions welcome!
